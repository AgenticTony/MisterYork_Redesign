{
  "feature": "Add robots.txt and security.txt for Security Controls",
  "workflow_type": "simple",
  "workflow_rationale": "Single-service task with no complex dependencies. Just adding two static text files to the public directory.",
  "phases": [
    {
      "id": "phase-1-robots-txt",
      "name": "Add robots.txt",
      "type": "implementation",
      "description": "Create robots.txt file in public directory to control crawler behavior",
      "depends_on": [],
      "parallel_safe": true,
      "subtasks": [
        {
          "id": "subtask-1-1",
          "description": "Create robots.txt file in public/ directory",
          "service": "frontend",
          "files_to_create": [
            "public/robots.txt"
          ],
          "files_to_modify": [],
          "patterns_from": [],
          "verification": {
            "type": "command",
            "command": "test -f public/robots.txt && echo 'robots.txt exists' || echo 'robots.txt missing'",
            "expected": "robots.txt exists"
          },
          "status": "completed"
        },
        {
          "id": "subtask-1-2",
          "description": "Verify robots.txt is accessible at /robots.txt endpoint",
          "service": "frontend",
          "files_to_modify": [],
          "files_to_create": [],
          "patterns_from": [],
          "verification": {
            "type": "api",
            "method": "GET",
            "url": "http://localhost:3000/robots.txt",
            "expected_status": 200
          },
          "status": "completed"
        }
      ]
    },
    {
      "id": "phase-2-security-txt",
      "name": "Add security.txt",
      "type": "implementation",
      "description": "Create security.txt file in public directory following RFC 9116",
      "depends_on": [],
      "parallel_safe": true,
      "subtasks": [
        {
          "id": "subtask-2-1",
          "description": "Create security.txt file in public/ directory",
          "service": "frontend",
          "files_to_create": [
            "public/security.txt"
          ],
          "files_to_modify": [],
          "patterns_from": [],
          "verification": {
            "type": "command",
            "command": "test -f public/security.txt && echo 'security.txt exists' || echo 'security.txt missing'",
            "expected": "security.txt exists"
          },
          "status": "pending"
        },
        {
          "id": "subtask-2-2",
          "description": "Verify security.txt is accessible at /security.txt endpoint",
          "service": "frontend",
          "files_to_modify": [],
          "files_to_create": [],
          "patterns_from": [],
          "verification": {
            "type": "api",
            "method": "GET",
            "url": "http://localhost:3000/security.txt",
            "expected_status": 200
          },
          "status": "pending"
        }
      ]
    }
  ],
  "verification_strategy": {
    "risk_level": "low",
    "skip_validation": false,
    "test_creation_phase": "none",
    "test_types_required": [],
    "security_scanning_required": false,
    "staging_deployment_required": false,
    "acceptance_criteria": [
      "robots.txt file exists in public/ directory",
      "robots.txt is accessible at /robots.txt URL",
      "security.txt file exists in public/ directory",
      "security.txt is accessible at /security.txt URL",
      "Both files contain appropriate content for the application"
    ],
    "verification_steps": [
      {
        "name": "Verify robots.txt file exists",
        "command": "test -f public/robots.txt",
        "expected_outcome": "File exists",
        "type": "command",
        "required": true,
        "blocking": true
      },
      {
        "name": "Verify security.txt file exists",
        "command": "test -f public/security.txt",
        "expected_outcome": "File exists",
        "type": "command",
        "required": true,
        "blocking": true
      },
      {
        "name": "Verify robots.txt endpoint",
        "command": "curl -s -o /dev/null -w '%{http_code}' http://localhost:3000/robots.txt",
        "expected_outcome": "200",
        "type": "api",
        "required": true,
        "blocking": true
      },
      {
        "name": "Verify security.txt endpoint",
        "command": "curl -s -o /dev/null -w '%{http_code}' http://localhost:3000/security.txt",
        "expected_outcome": "200",
        "type": "api",
        "required": true,
        "blocking": true
      }
    ],
    "reasoning": "Low risk change - only adding static text files. No code modifications required. Verification is simple file existence and HTTP endpoint checks."
  },
  "qa_acceptance": {
    "unit_tests": {
      "required": false,
      "commands": [],
      "minimum_coverage": null
    },
    "integration_tests": {
      "required": false,
      "commands": [],
      "services_to_test": []
    },
    "e2e_tests": {
      "required": false,
      "commands": [],
      "flows": []
    },
    "browser_verification": {
      "required": true,
      "pages": [
        {
          "url": "http://localhost:3000/robots.txt",
          "checks": [
            "file-loads",
            "valid-robots-txt-format"
          ]
        },
        {
          "url": "http://localhost:3000/security.txt",
          "checks": [
            "file-loads",
            "valid-security-txt-format"
          ]
        }
      ]
    },
    "database_verification": {
      "required": false,
      "checks": []
    }
  },
  "qa_signoff": null,
  "summary": {
    "total_phases": 2,
    "total_subtasks": 4,
    "services_involved": [
      "frontend"
    ],
    "parallelism": {
      "max_parallel_phases": 2,
      "parallel_groups": [
        {
          "phases": [
            "phase-1-robots-txt",
            "phase-2-security-txt"
          ],
          "reason": "Both phases are independent and create different files. No overlapping file modifications."
        }
      ],
      "recommended_workers": 2,
      "speedup_estimate": "2x faster than sequential"
    },
    "startup_command": "source auto-claude/.venv/bin/activate && python auto-claude/run.py --spec 012 --parallel 2"
  },
  "status": "in_progress",
  "planStatus": "in_progress",
  "updated_at": "2026-02-18T18:54:13.133Z"
}